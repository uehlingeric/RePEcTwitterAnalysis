{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Analysis of RePEc User and Mastodon Activity\n",
    "\n",
    "This notebook conducts an analysis of RePEc user activity, their interactions, and their mentions in Mastodon-related tweets. We focus on generating weekly user engagement datasets, mapping relationships between RePEc users, and creating a detailed timeline of interactions based on Mastodon tweet data.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. **Reading and Processing RePEc User Information**:\n",
    "    - Load `cleaned_RePEc_userinfo.csv` and `RePEc_userfollowing.csv` to map Twitter and RePEc IDs.\n",
    "    - Create a new `repec_following.csv` file that adds RePEc IDs for authors and followers, omitting rows without valid IDs.\n",
    "    \n",
    "2. **Generating Mastodon User Weekly Activity**:\n",
    "    - Analyze the `mastodon_tweets.csv` dataset to create a `week` column representing numbered weeks since January 1, 2022.\n",
    "    - Identify unique RePEc users tweeting in each week and save the results to `mastodon_user_week.csv`.\n",
    "\n",
    "3. **Creating Mentions Data**:\n",
    "    - Use `mastodon_user_week.csv` and `userinfo_df` to track weekly mentions of RePEc users.\n",
    "    - Create a dataset (`mentions.csv`) that logs whether a user was mentioned each week, marked with 0 or 1 for each week column.\n",
    "\n",
    "4. **Creating Mastodon User Week Interacted Data**:\n",
    "    - Use `mastodon_user_week.csv` and `repec_following.csv` to extend user interactions by including followers of mentioned users.\n",
    "    - Save the extended dataset to `mastodon_user_week_interacted.csv`.\n",
    "\n",
    "5. **Creating Interacted Data**:\n",
    "    - Use `mastodon_user_week_interacted.csv` to update user interaction records.\n",
    "    - Track mentions and interactions in `interacted.csv`, considering both direct user activity and interactions through followers.\n",
    "\n",
    "**Author: Eric Uehling**  \n",
    "*Date: 7.13.24*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Reading and Processing RePEc User Information and Following Data\n",
    "\n",
    "### Overview\n",
    "In this step, we will:\n",
    "1. Read in two CSV files:\n",
    "   - `cleaned_RePEc_userinfo.csv`: Contains user information, including Twitter and RePEc IDs.\n",
    "   - `RePEc_userfollowing.csv`: Contains information about which users are following whom.\n",
    "2. Create a new CSV file named `repec_following.csv`, which will be a modified version of `RePEc_userfollowing.csv`. This new file will include additional columns `repec_id` and `follower_repec_id`, corresponding to the RePEc IDs of the `author_id` and `follower_id`.\n",
    "3. Map the corresponding RePEc IDs from the `cleaned_RePEc_userinfo.csv` to each row in the following data.\n",
    "4. If either `author_id` or `follower_id` does not have a corresponding RePEc ID, we will skip that row.\n",
    "5. Finally, we will save the output to a new CSV file called `repec_following.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved the file to ../data/csv/repec_following.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the datasets\n",
    "userinfo_df = pd.read_csv('../data/csv/cleaned_RePEc_userinfo.csv')\n",
    "userfollowing_df = pd.read_csv('../data/csv/RePEc_userfollowing.csv')\n",
    "\n",
    "# Create a dictionary for quick lookup of RePEc IDs\n",
    "repec_id_dict = userinfo_df.set_index('id')['RePEc_id'].to_dict()\n",
    "\n",
    "# Step 2: Map the corresponding RePEc IDs and filter the dataframe in one step\n",
    "userfollowing_df['repec_id'] = userfollowing_df['author_id'].map(repec_id_dict)\n",
    "userfollowing_df['follower_repec_id'] = userfollowing_df['follower_id'].map(repec_id_dict)\n",
    "\n",
    "# Remove rows with missing RePEc IDs in one step\n",
    "userfollowing_df.dropna(subset=['repec_id', 'follower_repec_id'], inplace=True)\n",
    "\n",
    "# Step 3: Output the file\n",
    "output_path = '../data/csv/repec_following.csv'\n",
    "userfollowing_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Successfully saved the file to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generating the Mastodon User Weekly Activity Data\n",
    "\n",
    "### Overview\n",
    "In this step, we will:\n",
    "1. Use the `mastodon_tweets` dataset to create a new column named `week`. This column will represent the numbered week starting from January 1, 2022. For example, if a tweet was created on '2022-11-18', it will be mapped to its corresponding week number in the year.\n",
    "2. Determine the maximum week number to define the range of weeks we will be working with. This will help us create the appropriate number of rows (e.g., 1 to 65 weeks).\n",
    "3. For each week, identify the unique `RePEc_id`s that correspond to the tweets created in that week. These IDs will be aggregated into lists, and we will populate the `repec_users` column with these lists.\n",
    "4. Finally, we will save the resulting dataset to a new CSV file named `mastodon_user_week.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved the file to ../data/csv/mastodon_user_week.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the Mastodon tweets dataset\n",
    "mastodon_tweets_df = pd.read_csv('../data/csv/mastodon_tweets.csv')\n",
    "\n",
    "# Step 1: Create the 'week' column\n",
    "# Convert 'created_at' to datetime\n",
    "mastodon_tweets_df['created_at'] = pd.to_datetime(mastodon_tweets_df['created_at'])\n",
    "\n",
    "# Define the start date\n",
    "start_date = datetime(2022, 1, 1)\n",
    "\n",
    "# Calculate the week number\n",
    "mastodon_tweets_df['week'] = mastodon_tweets_df['created_at'].apply(\n",
    "    lambda x: (x - start_date).days // 7 + 1\n",
    ")\n",
    "\n",
    "# Step 2: Determine the max week number\n",
    "max_week = mastodon_tweets_df['week'].max()\n",
    "\n",
    "# Initialize a list to store the data for the new CSV file\n",
    "week_data = []\n",
    "\n",
    "# Step 3: Generate the list of unique RePEc IDs for each week\n",
    "for week_num in range(1, max_week + 1):\n",
    "    # Filter tweets for the current week\n",
    "    weekly_tweets = mastodon_tweets_df[mastodon_tweets_df['week'] == week_num]\n",
    "    \n",
    "    # Extract unique RePEc IDs\n",
    "    unique_repec_ids = weekly_tweets['RePEc_id'].unique().tolist()\n",
    "    \n",
    "    # Append the result to the list\n",
    "    week_data.append({\n",
    "        'week': week_num,\n",
    "        'repec_users': unique_repec_ids\n",
    "    })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "week_df = pd.DataFrame(week_data)\n",
    "\n",
    "# Step 4: Output the file\n",
    "output_path = '../data/csv/mastodon_user_week.csv'\n",
    "week_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Successfully saved the file to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Creating the Mentions Data File\n",
    "\n",
    "### Overview\n",
    "In this step, we will:\n",
    "1. Identify the maximum week number from the `mastodon_user_week.csv` file to determine how many week columns are needed in the `mentions.csv` file.\n",
    "2. For each user in the `userinfo_df` dataset, create a row in `mentions.csv` with their `author_id`, `repec_id`, `number_of_followers`, and `following_count`, followed by week columns (`week1`, `week2`, etc.) initialized to '0'.\n",
    "3. For each week, identify if the user exists in the `repec_users` list from `mastodon_user_week.csv`. If the user is mentioned in a particular week, the corresponding week column value should be changed from '0' to '1'.\n",
    "4. Finally, we will save the resulting dataset to a new CSV file named `mentions.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved the file to ../data/csv/mentions.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the mastodon_user_week and userinfo datasets\n",
    "mastodon_user_week_df = pd.read_csv('../data/csv/mastodon_user_week.csv')\n",
    "userinfo_df = pd.read_csv('../data/csv/cleaned_RePEc_userinfo.csv')\n",
    "\n",
    "# Identify the maximum week number\n",
    "max_week = mastodon_user_week_df['week'].max()\n",
    "\n",
    "# Initialize the columns for the mentions.csv file\n",
    "week_columns = [f'week{week_num}' for week_num in range(1, max_week + 1)]\n",
    "\n",
    "# Create the mentions DataFrame with initial data\n",
    "mentions_df = userinfo_df[['id', 'RePEc_id', 'followers_count', 'following_count']].copy()\n",
    "mentions_df.columns = ['author_id', 'repec_id', 'number_of_followers', 'following_count']\n",
    "\n",
    "# Add week columns initialized to 0\n",
    "for week_col in week_columns:\n",
    "    mentions_df[week_col] = 0\n",
    "\n",
    "# Step 2: Update the mentions DataFrame based on the mastodon_user_week data\n",
    "for _, row in mastodon_user_week_df.iterrows():\n",
    "    week_num = row['week']\n",
    "    repec_users = row['repec_users'][1:-1].replace(\"'\", \"\").split(\", \")  # Convert string representation of list to list\n",
    "    \n",
    "    # Identify users mentioned in this week\n",
    "    mentions_df.loc[mentions_df['repec_id'].isin(repec_users), f'week{week_num}'] = 1\n",
    "\n",
    "# Step 3: Output the file\n",
    "output_path = '../data/csv/mentions.csv'\n",
    "mentions_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Successfully saved the file to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Creating the Mastodon User Week Interacted Data File\n",
    "\n",
    "### Overview\n",
    "In this step, we will:\n",
    "1. Use the `mastodon_tweets` dataset to create a new column named `week`. This column will represent the numbered week starting from January 1, 2022. For example, if a tweet was created on '2022-11-18', it will be mapped to its corresponding week number in the year.\n",
    "2. Determine the maximum week number to define the range of weeks we will be working with. This will help us create the appropriate number of rows (e.g., 1 to 65 weeks).\n",
    "3. For each week, identify and create a list of unique `RePEc_id`s that correspond to the tweets created in that week. These IDs will be aggregated into lists, and we will populate the `repec_users` column with these lists.\n",
    "4. Read in the `repec_following.csv` file and for each week, extend the `repec_users` list to include `RePEc_id`s of users who follow those already in the list.\n",
    "5. Finally, we will save the resulting dataset to a new CSV file named `mastodon_user_week_interacted.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved the file to ../data/csv/mastodon_user_week_interacted.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the necessary datasets\n",
    "mastodon_tweets_df = pd.read_csv('../data/csv/mastodon_tweets.csv')\n",
    "repec_following_df = pd.read_csv('../data/csv/repec_following.csv')\n",
    "\n",
    "# Convert 'created_at' to datetime\n",
    "mastodon_tweets_df['created_at'] = pd.to_datetime(mastodon_tweets_df['created_at'])\n",
    "\n",
    "# Define the start date\n",
    "start_date = datetime(2022, 1, 1)\n",
    "\n",
    "# Calculate the week number\n",
    "mastodon_tweets_df['week'] = mastodon_tweets_df['created_at'].apply(\n",
    "    lambda x: (x - start_date).days // 7 + 1\n",
    ")\n",
    "\n",
    "# Step 2: Determine the max week number\n",
    "max_week = mastodon_tweets_df['week'].max()\n",
    "\n",
    "# Initialize a list to store the data for the new CSV file\n",
    "week_data = []\n",
    "\n",
    "# Step 3: Generate the list of unique RePEc IDs for each week\n",
    "for week_num in range(1, max_week + 1):\n",
    "    # Filter tweets for the current week\n",
    "    weekly_tweets = mastodon_tweets_df[mastodon_tweets_df['week'] == week_num]\n",
    "    \n",
    "    # Extract unique RePEc IDs\n",
    "    unique_repec_ids = weekly_tweets['RePEc_id'].unique().tolist()\n",
    "    \n",
    "    # Append the result to the list\n",
    "    week_data.append({\n",
    "        'week': week_num,\n",
    "        'repec_users': unique_repec_ids\n",
    "    })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "week_df = pd.DataFrame(week_data)\n",
    "\n",
    "# Step 4: Read the repec_following.csv and extend the repec_users lists\n",
    "# Create a dictionary for quick lookup of followers\n",
    "following_dict = repec_following_df.groupby('repec_id')['follower_repec_id'].apply(list).to_dict()\n",
    "\n",
    "for _, row in week_df.iterrows():\n",
    "    week_repec_users = set(row['repec_users'])\n",
    "    extended_repec_users = set(week_repec_users)  # Start with the current week's users\n",
    "    \n",
    "    for repec_id in week_repec_users:\n",
    "        if repec_id in following_dict:\n",
    "            extended_repec_users.update(following_dict[repec_id])\n",
    "    \n",
    "    # Update the row's repec_users with the extended list\n",
    "    week_df.at[_, 'repec_users'] = list(extended_repec_users)\n",
    "\n",
    "# Step 5: Output the file\n",
    "output_path = '../data/csv/mastodon_user_week_interacted.csv'\n",
    "week_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Successfully saved the file to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Creating the Interacted Data File Using `mastodon_user_week_interacted.csv`\n",
    "\n",
    "### Overview\n",
    "In this step, we will:\n",
    "1. Identify the maximum week number from the `mastodon_user_week_interacted.csv` file to determine how many week columns are needed in the `interacted.csv` file.\n",
    "2. For each user in the `userinfo_df` dataset, create a row in `interacted.csv` with their `author_id`, `repec_id`, `number_of_followers`, and `following_count`, followed by week columns (`week1`, `week2`, etc.) initialized to '0'.\n",
    "3. For each week, check if the user or any of the accounts they follow (from `repec_following.csv`) exists in the `repec_users` list from `mastodon_user_week_interacted.csv`. If the user or a followed account is mentioned in a particular week, the corresponding week column value should be changed from '0' to '1'.\n",
    "4. Finally, we will save the resulting dataset to a new CSV file named `interacted.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved the file to ../data/csv/interacted.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the necessary datasets\n",
    "mastodon_user_week_interacted_df = pd.read_csv('../data/csv/mastodon_user_week_interacted.csv')\n",
    "userinfo_df = pd.read_csv('../data/csv/cleaned_RePEc_userinfo.csv')\n",
    "\n",
    "# Identify the maximum week number\n",
    "max_week = mastodon_user_week_interacted_df['week'].max()\n",
    "\n",
    "# Initialize the columns for the interacted.csv file\n",
    "week_columns = [f'week{week_num}' for week_num in range(1, max_week + 1)]\n",
    "\n",
    "# Create the interacted DataFrame with initial data\n",
    "interacted_df = userinfo_df[['id', 'RePEc_id', 'followers_count', 'following_count']].copy()\n",
    "interacted_df.columns = ['author_id', 'repec_id', 'number_of_followers', 'following_count']\n",
    "\n",
    "# Add week columns initialized to 0\n",
    "for week_col in week_columns:\n",
    "    interacted_df[week_col] = 0\n",
    "\n",
    "# Step 2: Update the interacted DataFrame based on the mastodon_user_week_interacted data\n",
    "for _, row in mastodon_user_week_interacted_df.iterrows():\n",
    "    week_num = row['week']\n",
    "    repec_users = row['repec_users'][1:-1].replace(\"'\", \"\").split(\", \")  # Convert string representation of list to list\n",
    "    \n",
    "    # Update the DataFrame if the user exists in the repec_users list\n",
    "    interacted_df.loc[interacted_df['repec_id'].isin(repec_users), f'week{week_num}'] = 1\n",
    "\n",
    "# Step 3: Output the file\n",
    "output_path = '../data/csv/interacted.csv'\n",
    "interacted_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Successfully saved the file to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
